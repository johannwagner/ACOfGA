\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Automatic Code Optimizations on GPU Architectures}

\author{
	\IEEEauthorblockN{Johann Wagner}
	\IEEEauthorblockA{
		\textit{Otto-von-Guericke Universit√§t} \\
		Magdeburg, Germany\\
		johann.wagner@st.ovgu.de
	}
}


\maketitle

\begin{abstract}

\end{abstract}

\begin{IEEEkeywords}
GPU Compiler Optimizations
\end{IEEEkeywords}

\section{Introduction}

	% What is the problem?
		% Complex Calculations, that does not share much data and can be multithreaded.
		% Processing with GPU for Acceleration
		% Optimization is quite basic for GPGPU Compiler at the moment.

	% Why is it interesting and important?
		% Speed up GPGPU code
		% Programming GPU is more complex as CPU Programming
			% Multithreading 
			% 6 Different Memory Types
			% Hard to write performant code
			
	% Why is it hard? (E.g., why do naive approaches fail?)
		% ?
	% Why hasn't it been solved before? (Or, what's wrong with previous proposed solutions? How does mine differ?)
		% No qualitative comparisions between different GPU Optimizations 
	% What are the key components of my approach and results? Also include any specific limitations.
		% Optimization for Memory Access Times
		% Only Compiler Optimization

	

\section{Background}

	\subsection{General Purpose Computation on GPUs}
	
		% Explanation, why GPGPU is interessting
			% Multithreading
		% Advantages, Disadvantages of GPGPU
			% Transfer
			% Complexity
			% Speed
			% Threads
			
	\subsection{NVIDIA CUDA}
		
		% General Explanation
			% CUDA is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.
		% Advantages of CUDA 
	
	\subsection{Memory Seperation in CUDA}
		
		% Explanation about the six different memory types.
		% Categorization with Size, Availability, Speed, Access Time 
		
		% Register
		% Local Memory
		% Shared Memory
		% Global Memory
		% Constant Memory
		% Texture Memory
		
		

\section{Body}

	% Introduction
	% Why do we want to optimize Memory Access
	% Why do we want to do it automagically
	

	
	\subsection{Thread-Block Merging}
		
		% General Explanation 
		% Graphic for Explanation
	
	\subsection{Thread Merging}
		
		% General Explanation 
		% Difference to Thread Block Merging
		% Graphic for Explanation
		
	\subsection{Data Prefetching}
		
		% General Explanation
		
	\subsection{Partition Camping}
		
		% General Explanation
		% Graphics
			% Not that easy to understand

\section{Evaluation}

	% Go through Categories and categorize every Optimization for every Category and explain why.
		% Categories
		% Use Cases (special or general)
		% Efficiency
		% Difficulty
		% Code Examples (?)
		% Error Case
	
	
\section{Related Work}

\section{Conclusion}

\begin{thebibliography}{00}
\bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.

\end{thebibliography}

\end{document}

